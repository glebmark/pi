Why does Kubernetes require a static IP on the node?	Kubernetes binds certificates to the node's IP. If the IP changes (DHCP lease renewal), the API server certificate becomes invalid and the cluster breaks.
What are two ways to ensure a stable IP for a Kubernetes node?	1) Set a static IP via NetworkManager on the Pi. 2) Set a DHCP reservation on the router for the Pi's MAC address.
Why does Kubernetes require swap to be disabled?	Kubernetes uses its own memory management (resource limits, pod eviction). Swap interferes with accurate memory accounting and can cause unpredictable latency.
Why exactly does swap interfere with Kubernetes resource management?	With swap, a pod that exceeds its memory limit doesn't get OOM-killed — it gets swapped, becoming extremely slow instead of failing. This breaks the predictability of QoS classes and makes resource guarantees meaningless.
What two kernel modules does Kubernetes networking require?	`overlay` (for container filesystems) and `br_netfilter` (for iptables to see bridged traffic).
What three sysctl parameters must be set to 1 for Kubernetes networking?	net.bridge.bridge-nf-call-iptables, net.bridge.bridge-nf-call-ip6tables, net.ipv4.ip_forward
What does `net.ipv4.ip_forward = 1` enable?	IP packet forwarding between network interfaces — required for pod-to-pod traffic routing.
What does `net.bridge.bridge-nf-call-iptables = 1` do?	Makes bridged traffic pass through iptables rules, allowing Kubernetes network policies and service routing to work on bridge interfaces.
Why does bridged traffic need `br_netfilter` for Kubernetes?	Without br_netfilter, traffic between containers on the same bridge bypasses iptables entirely. Kubernetes needs iptables to process this traffic for Services (kube-proxy rules) and NetworkPolicies.
Why does Raspberry Pi OS disable the memory cgroup controller by default?	To save overhead. It must be explicitly enabled for Kubernetes (which needs it for resource limits and pod eviction).
How do you enable the memory cgroup controller on Raspberry Pi?	Append `cgroup_enable=memory` to /boot/firmware/cmdline.txt (on the same line) and reboot.
What is the CRI (Container Runtime Interface)?	A Kubernetes API specification that defines how the kubelet communicates with container runtimes. It abstracts the runtime so Kubernetes isn't tied to a specific implementation.
Name three CRI-compatible container runtimes.	containerd, CRI-O, and Mirantis Container Runtime (formerly Docker Engine with dockershim).
What critical containerd setting must be changed for Kubernetes?	SystemdCgroup must be set to `true` (in /etc/containerd/config.toml) so containerd uses the systemd cgroup driver.
What does the `SystemdCgroup = true` setting in containerd do?	Tells containerd (via runc) to use the systemd cgroup driver instead of the cgroupfs driver. This must match kubelet's cgroup driver — systemd is the recommended default since Kubernetes 1.22+.
What happens if containerd and kubelet use different cgroup drivers?	Resource tracking becomes inconsistent. Containers may not respect limits properly, and the node can become unstable as two systems try to manage cgroups independently.
What is the cgroupfs driver?	Directly manipulates cgroup filesystem paths (/sys/fs/cgroup/) to create and manage groups. Simple but doesn't integrate with systemd's cgroup tree, leading to two competing cgroup managers on systemd-based systems.
What is the systemd cgroup driver?	Creates and manages cgroups through systemd transient units (using systemd API). This integrates with systemd's single cgroup hierarchy, avoiding conflicts. Recommended for all systemd-based Linux distributions.
What is the sandbox (pause) image in containerd?	A minimal container that holds the network namespace for each pod. Every pod starts with a pause container that other containers in the pod join.
What is crictl?	A CLI tool for interacting with CRI-compatible container runtimes. Useful for debugging container and pod issues on the node.
What file configures which container runtime socket crictl connects to?	/etc/crictl.yaml
What is the difference between `ctr` and `crictl`?	`ctr` is containerd's native CLI (talks directly to containerd API). `crictl` talks via the CRI interface and understands Kubernetes concepts like pods. crictl is better for K8s debugging.
What does `sudo crictl info` show?	Runtime status information: CRI config, CNI status, cgroup driver, runtime handlers, and error conditions. Useful to verify containerd + CRI are working.
What does `crictl pods` show?	Lists all pods managed by the CRI runtime on the node, with their state, name, namespace, and age.
What does `crictl ps` show?	Lists all containers on the node (similar to docker ps), with their state, image, pod, and creation time.
What does `crictl images` show?	Lists all container images stored locally by the container runtime.
What port does the Kubernetes API server listen on?	6443/tcp
What ports does etcd use?	2379 (client) and 2380 (peer communication).
What is the Kubernetes NodePort range?	30000–32767/tcp
What port does the Kubelet API use?	10250/tcp
What port does kube-scheduler listen on?	10259/tcp
What port does kube-controller-manager listen on?	10257/tcp
What are ports 4240 and 8472 used for with Cilium?	4240/tcp is Cilium health checking between nodes. 8472/udp is VXLAN overlay traffic for pod-to-pod communication across nodes.
What are ports 4244 and 4245 used for with Cilium?	4244/tcp is Hubble (Cilium's observability layer) for network flow monitoring. 4245/tcp is Hubble Relay for aggregating Hubble data across nodes.
What is port 7946 used for with MetalLB?	MetalLB's memberlist protocol (both TCP and UDP) — used for node-to-node communication to coordinate which node announces which LoadBalancer IP.
Why is accurate time synchronisation critical for Kubernetes?	Certificate validation and etcd consensus depend on synchronized clocks. Clock skew can cause TLS errors and etcd leader election failures.
What is the kubelet?	The primary node agent that runs on every Kubernetes node. It receives pod specs from the API server, ensures the containers described are running and healthy, and reports node/pod status back.
How does the kubelet start containers?	kubelet sends gRPC requests to the container runtime (containerd) via the CRI socket. containerd pulls images, sets up networking (via CNI), creates the sandbox (pause container), and spawns app containers via runc.
What is the Kubernetes control plane?	The set of components that make global decisions about the cluster: kube-apiserver (API), etcd (state), kube-scheduler (placement), kube-controller-manager (reconciliation loops).
What does the kube-apiserver do?	The front door to the Kubernetes cluster. It exposes the Kubernetes API (REST/gRPC), validates requests, handles authentication/authorization, and is the only component that talks directly to etcd.
What is etcd?	A distributed, strongly-consistent key-value store used by Kubernetes to persist all cluster state — pods, services, configs, secrets, node registrations, etc. Uses the Raft consensus protocol.
What is the Raft consensus protocol (used by etcd)?	An algorithm for maintaining a replicated log across a cluster of machines. A leader is elected; it replicates writes to followers. Requires a quorum (majority) of nodes to agree before committing.
Why does etcd need a quorum?	Raft requires a majority of nodes (e.g., 2 of 3, 3 of 5) to agree on writes. This ensures consistency even if some nodes fail. Without a quorum, etcd becomes read-only to prevent split-brain.
What is a split-brain problem in distributed systems?	When a network partition causes two groups of nodes to independently accept writes, leading to divergent state. Raft/etcd prevents this by requiring a quorum — only one partition can have a majority.
Why does etcd need accurate time synchronisation?	Raft uses leader leases with timeouts. If clocks are skewed, nodes may prematurely think the leader has failed and trigger unnecessary elections, causing instability.
What does the kube-scheduler do?	Watches for newly created pods with no assigned node, evaluates node fitness (resource availability, affinity/anti-affinity rules, taints/tolerations, topology), and binds the pod to the best node.
What are taints and tolerations in Kubernetes?	Taints are applied to nodes to repel pods. Tolerations are applied to pods to allow scheduling on tainted nodes. Used to dedicate nodes for specific workloads (e.g., control plane, GPU nodes).
What does the kube-controller-manager do?	Runs a collection of control loops (controllers) that watch cluster state via the API server and make changes to move from current state to desired state. Each controller handles one concern.
What is the reconciliation loop pattern in Kubernetes?	Controllers continuously: 1) observe current state, 2) compare to desired state (from the spec), 3) take action to close the gap. This is the core of Kubernetes' declarative model.
What are the Kubernetes QoS (Quality of Service) classes?	Three classes based on resource requests/limits: 1) Guaranteed (requests == limits) 2) Burstable (at least one request set, limits differ) 3) BestEffort (no requests or limits).
How does Kubernetes use QoS classes for eviction?	When a node runs low on resources, the kubelet evicts pods in order: BestEffort first, then Burstable, then Guaranteed last.
What is pod eviction in Kubernetes?	When a node is under resource pressure (memory, disk, PIDs), the kubelet proactively terminates pods to reclaim resources. It follows QoS class ordering.
What is the Kubernetes pod networking model?	Every pod gets its own unique IP address. Pods can communicate with any other pod across any node without NAT. The underlying network (CNI) creates a flat network where all pod IPs are routable.
What is a CNI (Container Network Interface)?	A specification and set of plugins that configure networking for containers. When a pod starts, the kubelet calls the CNI plugin to set up the pod's network interface, assign an IP, and configure routes.
How does CNI get invoked?	When kubelet creates a pod, it tells containerd to create the sandbox. containerd calls the CNI plugin binary (from /opt/cni/bin/) with network config from /etc/cni/net.d/.
What is a pod CIDR vs. a service CIDR?	Pod CIDR (e.g., 10.244.0.0/16) is the IP range for pod IPs — real routable addresses. Service CIDR (e.g., 10.96.0.0/12) is for virtual ClusterIP addresses — not routable, translated by kube-proxy/Cilium.
What are the Kubernetes Service types?	ClusterIP (internal virtual IP, default), NodePort (exposes on each node's IP at a static port), LoadBalancer (provisions an external LB), ExternalName (CNAME alias to an external DNS name).
What does kube-proxy do?	Runs on every node and implements Service networking. It watches Service and Endpoint objects, then programs iptables/IPVS rules to translate Service virtual IPs (ClusterIPs) to actual pod IPs.
What are the kube-proxy modes?	iptables mode (default, creates iptables DNAT rules for each Service), IPVS mode (uses Linux IPVS for better performance at scale), and the deprecated userspace mode.
Why is IPVS mode better than iptables mode for kube-proxy?	iptables rules are O(n) — every packet walks a chain of rules. IPVS uses hash tables for O(1) lookup, handling thousands of services much more efficiently.
What is the Kubernetes API server's PKI (Public Key Infrastructure)?	kubeadm generates a CA and issues certificates for: API server, kubelet, etcd, front-proxy, service account signing. All TLS communication is secured by these certificates.
Where does kubeadm store cluster PKI files?	/etc/kubernetes/pki/ — contains ca.crt, ca.key, apiserver.crt, apiserver.key, etcd/ca.crt, front-proxy-ca.crt, sa.key, sa.pub, and more.
What is the API server certificate's SAN (Subject Alternative Name)?	A certificate field listing all names/IPs the certificate is valid for. Includes the hostname, kubernetes.default, the service CIDR's first IP, and the node's IP — this is why changing the node IP breaks the cluster.
Why did Kubernetes deprecate dockershim?	Docker is a full container platform, but Kubernetes only needed the runtime part. containerd (Docker's own runtime) speaks CRI natively, so the dockershim adapter became unnecessary.
What is the container runtime stack on a Kubernetes node? (top to bottom)	kubelet → CRI (gRPC API) → containerd (image management, lifecycle) → containerd-shim (process management) → runc (Linux namespaces + cgroups) → your container process.
What are Kubernetes static pods?	Pods managed directly by the kubelet on a specific node, not through the API server. Defined as YAML files in /etc/kubernetes/manifests/. kubeadm uses static pods for control plane components.
Why does kubeadm use static pods for the control plane?	Static pods are managed by the local kubelet, not by the cluster itself. This solves the chicken-and-egg problem: you need the API server running before you can create pods via the API.
What does `kubeadm init` actually do? (high-level steps)	1) Pre-flight checks 2) Generate PKI 3) Generate kubeconfig files 4) Create static pod manifests 5) Wait for control plane 6) Apply ConfigMaps 7) Setup bootstrap tokens 8) Install CoreDNS.
What is /etc/kubernetes/admin.conf?	A kubeconfig file generated by kubeadm with cluster admin credentials (client certificate). Copied to ~/.kube/config for kubectl.
What is a kubeconfig file?	A YAML file that defines clusters (API server URL + CA), users (credentials), and contexts (cluster + user combinations). kubectl uses it to know where and how to connect.
What are Kubernetes node requirements? (hardware + config)	2+ CPUs, 2+ GB RAM, unique hostname + MAC + product_uuid across nodes, no swap, certain ports open, container runtime installed, kubelet + kubeadm installed.
What is a Kubernetes node's product_uuid and why must it be unique?	A hardware UUID at /sys/class/dmi/id/product_uuid. Kubernetes uses it to uniquely identify nodes. Duplicate UUIDs (common in cloned VMs) cause registration conflicts.
What happens when you run `kubeadm join`?	The worker: 1) contacts the API server using the bootstrap token, 2) downloads the cluster CA cert, 3) verifies it against the hash, 4) gets a kubelet client certificate, 5) starts kubelet which registers the node.
What is a bootstrap token in kubeadm?	A short-lived token (format: abcdef.0123456789abcdef) used to authenticate new nodes during cluster join. Expires after 24 hours by default.
What is kubeadm?	The official Kubernetes tool for bootstrapping a cluster. Handles certificate generation, static pod manifests, etcd setup, and component configuration. Does NOT manage infrastructure or install kubelet/kubectl.
What are the three Kubernetes packages installed on a node?	kubeadm (cluster bootstrap tool), kubelet (node agent that runs pods), kubectl (CLI for interacting with the cluster API).
Why pin kubeadm, kubelet, and kubectl versions with `apt-mark hold`?	To prevent accidental version upgrades via `apt upgrade`. Kubernetes requires coordinated version upgrades.
Why does kubelet crash-loop before `kubeadm init`?	kubelet tries to connect to the API server which doesn't exist yet. It keeps restarting until kubeadm creates the control plane. This is normal.
Why must kubeadm and containerd agree on the pause (sandbox) image?	The pause image creates the pod's network namespace. If they disagree, containerd may pull one image while kubeadm expects another, causing init failures.
What does `kubeadm config images pull` do?	Pre-downloads all container images needed for the control plane. Avoids timeouts during `kubeadm init`.
What does the `--pod-network-cidr` flag in `kubeadm init` do?	Specifies the CIDR range for pod IP addresses (e.g., 10.244.0.0/16). The CNI plugin manages this range and assigns IPs from it.
What does `--skip-phases=addon/kube-proxy` do?	Tells kubeadm to skip installing kube-proxy during initialization. Used when Cilium replaces kube-proxy's functionality with eBPF.
What is the control plane taint and why remove it on a single-node cluster?	The taint `node-role.kubernetes.io/control-plane:NoSchedule` prevents workloads from scheduling on control plane nodes. Remove it so pods can run on the only node.
What is Helm?	A package manager for Kubernetes. Helm charts are templated bundles of Kubernetes manifests. Handles versioning, upgrades, rollbacks, and configuration.
What is a Helm chart?	A package of templated Kubernetes manifests plus metadata (Chart.yaml, values.yaml). Supports versioning, dependencies, and customisation via values.
What is a Helm release?	A specific instance of a chart deployed to a cluster. You can have multiple releases of the same chart. Each release tracks its revision history for rollbacks.
What does `helm install` vs `helm upgrade` vs `helm upgrade --install` do?	`install`: creates a new release (fails if exists). `upgrade`: updates existing (fails if missing). `upgrade --install`: creates if new, upgrades if existing — idempotent.
Why does `helm upgrade --reuse-values` exist?	Preserves all previously set Helm values and only applies the new `--set` flags. Without it, an upgrade would reset all values to chart defaults.
What is Cilium?	An eBPF-based CNI plugin for Kubernetes. Provides pod networking, network policy enforcement, load balancing, and can replace kube-proxy using eBPF programs in the kernel.
What is eBPF?	Extended Berkeley Packet Filter — a technology that lets you run sandboxed programs inside the Linux kernel without changing kernel source code. Used by Cilium for networking, security, and observability.
Why does Cilium's envoy component crash on Raspberry Pi 4?	The Cortex-A72 CPU has a 39-bit virtual address space, but Envoy's TCMalloc memory allocator assumes 48-bit. The mmap calls fail.
What is Cilium's envoy component used for?	L7 (application-layer) network policy enforcement — HTTP-aware traffic filtering. Not needed for basic L3/L4 networking and kube-proxy replacement.
What does `kubeProxyReplacement=true` do in Cilium?	Enables Cilium's eBPF-based replacement for kube-proxy. Handles Service ClusterIP translation, NodePort, and LoadBalancer traffic using eBPF instead of iptables.
How do L3, L4, and L7 relate to Kubernetes network policies?	L3 policies filter by IP/CIDR. L4 policies filter by IP + port/protocol. L7 policies filter by application content (HTTP path, headers). Cilium supports all three; L7 requires Envoy.
What layer does kube-proxy / Cilium's kube-proxy replacement operate at?	L3/L4 — translates Service ClusterIPs to pod IPs based on port numbers using DNAT.
What is MetalLB?	A bare-metal load balancer for Kubernetes. In L2 mode, it assigns external IPs from a configured pool to LoadBalancer Services and announces them via ARP on the local network.
Why is MetalLB needed on bare metal but not in cloud?	Cloud providers have built-in load balancers. On bare metal, there's no such infrastructure — MetalLB fills the gap using L2 (ARP) or BGP announcements.
How does MetalLB L2 mode work?	One node becomes the "leader" for each LoadBalancer IP. It responds to ARP requests for that IP, making the router send traffic to that node.
What layer does MetalLB L2 mode operate at?	Layer 2 — it responds to ARP requests to claim IP addresses on the local Ethernet segment.
What is the difference between MetalLB L2 mode and BGP mode?	L2: ARP on local segment — simple, single-leader, one subnet. BGP: announces routes to upstream routers — scales better, multi-path, requires BGP-capable routers.
What is an IPAddressPool in MetalLB?	A CRD that defines a range of IP addresses MetalLB can assign to LoadBalancer Services.
What is an L2Advertisement in MetalLB?	A CRD that tells MetalLB to advertise IPs from a specific IPAddressPool using Layer 2 (ARP/NDP) announcements.
Why should MetalLB's IP pool be outside the router's DHCP range?	If DHCP assigns one of MetalLB's IPs to another device, both would claim the same IP, causing network conflicts.
What is the Gateway API?	The official successor to the Kubernetes Ingress API. Provides a role-oriented, extensible model with GatewayClass, Gateway, and HTTPRoute resources.
What are the three main Gateway API resources?	GatewayClass (defines which controller handles Gateways), Gateway (a load balancer instance), HTTPRoute/GRPCRoute (routing rules).
How does Gateway API improve over Ingress?	Role separation (infra vs app teams), multi-protocol support (HTTP, gRPC, TCP, TLS), standardized across implementations, better extensibility via policy attachment.
What is Envoy Gateway?	A CNCF project that implements the Kubernetes Gateway API using Envoy proxy as the data plane.
What is Envoy proxy?	A high-performance L4/L7 proxy designed for cloud-native applications. Handles load balancing, routing, TLS, observability. Used as data plane in service meshes and gateways.
What is an HTTPRoute?	A Gateway API resource that defines HTTP routing rules and attaches to a Gateway via `parentRefs`. Managed by application teams.
What is a GatewayClass?	A cluster-scoped resource that defines a Gateway controller implementation. Similar to StorageClass — tells Kubernetes which controller manages Gateways of this class.
What is the Kubernetes Ingress resource?	A built-in API object (networking.k8s.io/v1) that defines HTTP(S) routing rules: hostname → path → backend Service. Requires a separate Ingress controller (nginx, Traefik, etc.) to actually implement the rules.
What is the nginx Ingress controller (ingress-nginx)?	A Kubernetes controller that watches Ingress resources and configures an nginx reverse proxy to route traffic accordingly. Maintained by the Kubernetes community (k8s.io/ingress-nginx). Now considered legacy in favor of Gateway API.
What is the difference between ingress-nginx and nginx-ingress?	ingress-nginx (kubernetes/ingress-nginx) is the community-maintained Kubernetes Ingress controller. nginx-ingress (nginxinc/kubernetes-ingress) is NGINX Inc's commercial version. Different projects, different repos, different config.
Why is the Ingress API considered limited compared to Gateway API?	1) No role separation — one resource controls both infra and app concerns. 2) Advanced features require non-portable annotations. 3) Only HTTP/HTTPS — no TCP/UDP/gRPC natively. 4) No standardized way to share a load balancer across namespaces. 5) No spec for traffic splitting percentages.
What are Ingress annotations and why are they a problem?	Controller-specific key-value pairs on Ingress objects (e.g., `nginx.ingress.kubernetes.io/rewrite-target`) that extend functionality beyond the basic spec. The problem: they're not portable — switching controllers means rewriting all annotations.
How does Gateway API solve the Ingress annotation problem?	Gateway API uses typed, structured resources (HTTPRoute fields, policy CRDs) instead of unstructured annotations. Features like header matching, request mirroring, and traffic weighting are part of the standard spec, portable across implementations.
What is the role separation in Gateway API that Ingress lacks?	Gateway API splits responsibilities: infra team manages GatewayClass + Gateway (which ports, which IPs, which TLS certs). App team manages HTTPRoute (which paths go to which Services). With Ingress, one resource controlled everything — app devs could accidentally change load balancer config.
How does an Ingress resource attach to its controller vs. how an HTTPRoute attaches to a Gateway?	Ingress uses `ingressClassName` to select a controller (global, implicit). HTTPRoute uses `parentRefs` to explicitly attach to a specific Gateway by name and namespace — more precise, supports attaching to multiple Gateways.
What is the Ingress equivalent of a GatewayClass?	IngressClass — but it's much simpler. IngressClass just names a controller. GatewayClass defines the controller AND allows attaching configuration (via parametersRef) like proxy settings, TLS policies, and resource templates.
What is the Ingress equivalent of a Gateway?	There's no direct equivalent. Ingress combines what Gateway API splits into Gateway (listener config, ports, TLS) and HTTPRoute (routing rules) in a single resource. The load balancer itself was implicitly created by the controller.
How do you define a simple hostname + path route in Ingress vs HTTPRoute?	Ingress: `spec.rules[].host` + `spec.rules[].http.paths[].path` + `spec.rules[].http.paths[].backend.service`. HTTPRoute: `spec.hostnames[]` + `spec.rules[].matches[].path` + `spec.rules[].backendRefs[]`. HTTPRoute also requires `parentRefs` to attach to a Gateway.
How does TLS termination differ between Ingress and Gateway API?	Ingress: TLS is configured directly on the Ingress resource via `spec.tls[].secretName`. Gateway API: TLS is configured on the Gateway listener — the infra team controls certificates. App teams (HTTPRoute) don't need access to TLS secrets.
What is `parentRefs` in an HTTPRoute?	The field that attaches an HTTPRoute to one or more Gateways. Specifies the Gateway name (and optionally namespace, section/listener name, and port). Replaces Ingress's `ingressClassName` with explicit, multi-target binding.
Can an HTTPRoute attach to multiple Gateways?	Yes — `parentRefs` is a list. An HTTPRoute can attach to multiple Gateways (e.g., internal and external), which was impossible with Ingress without duplicating the resource.
How does path matching differ between Ingress and HTTPRoute?	Ingress supports Exact and Prefix (with quirky nginx rewrite behavior). HTTPRoute supports Exact, PathPrefix, and RegularExpression — with clearer semantics and no need for rewrite annotations.
How does traffic splitting (canary/blue-green) work in Ingress vs Gateway API?	Ingress: requires controller-specific annotations (e.g., `nginx.ingress.kubernetes.io/canary-weight: "20"`). Gateway API: native `backendRefs[].weight` field — e.g., 80% to v1, 20% to v2. Standardized, portable.
What is header-based routing and how does it differ between Ingress and Gateway API?	Routing based on HTTP header values (e.g., route requests with `X-Version: beta` to a canary backend). Ingress: requires `canary-by-header` annotation (nginx-specific). Gateway API: native `spec.rules[].matches[].headers[]` field — standard across all implementations.
What HTTP matching capabilities does HTTPRoute have that Ingress doesn't?	HTTPRoute can match on: path (Exact/Prefix/Regex), headers (Exact/Regex), query parameters (Exact/Regex), and method (GET/POST/etc.) — all in the standard spec. Ingress only has basic path matching; everything else requires annotations.
What is request mirroring and does Ingress support it?	Sending a copy of live traffic to a secondary backend for testing/monitoring without affecting the response. Ingress: requires annotation (`nginx.ingress.kubernetes.io/mirror-target`). Gateway API: native `filters[].type: RequestMirror` field.
What are Gateway API policy attachments?	A pattern for extending Gateway API with custom policies (rate limiting, authentication, retry) by attaching policy CRDs to Gateway or HTTPRoute resources. Replaces Ingress's annotation-based extensibility with typed, validated resources.
Is the Ingress API officially deprecated?	Not formally removed, but the Kubernetes project considers it "frozen" — no new features will be added. Gateway API is the recommended replacement. Ingress will remain available for backward compatibility but new projects should use Gateway API.
What happens to existing Ingress resources if you switch to Gateway API?	They continue to work — Ingress and Gateway API can coexist in the same cluster. You can migrate incrementally, converting one Ingress at a time to HTTPRoute. Some controllers (like nginx) support both simultaneously.
What are the Gateway API resource equivalents for common Ingress patterns?	Ingress host rules → HTTPRoute hostnames. Ingress path rules → HTTPRoute matches. Ingress TLS → Gateway listener TLS. Ingress annotations for rewrites → HTTPRoute filters (URLRewrite). Ingress default backend → HTTPRoute with no matches.
What is CoreDNS?	The default cluster DNS server in Kubernetes. Runs as a Deployment in kube-system. Resolves Service names to ClusterIPs, enables service discovery.
How does Kubernetes DNS (CoreDNS) work?	CoreDNS runs as pods in kube-system. Every pod's /etc/resolv.conf points to the CoreDNS ClusterIP. Resolves: service-name.namespace.svc.cluster.local → Service ClusterIP.
What is the full DNS name for a Kubernetes Service named "echo" in the "default" namespace?	echo.default.svc.cluster.local — format: <service>.<namespace>.svc.<cluster-domain>
What is local-path-provisioner?	A Rancher project that provides dynamic PersistentVolume provisioning using local node storage. Creates directories on the host for each PVC.
What is a StorageClass in Kubernetes?	Defines a "class" of storage with specific characteristics (provisioner, parameters, reclaim policy). Used by PVCs to dynamically request storage.
What does making a StorageClass "default" do?	Any PVC that doesn't specify a `storageClassName` will automatically use the default StorageClass.
What is a PersistentVolume (PV) vs. a PersistentVolumeClaim (PVC)?	PV is a storage resource in the cluster. PVC is a request for storage by a pod. Dynamic provisioning auto-creates PVs via StorageClass when PVCs are created.
What is dynamic provisioning in Kubernetes storage?	When a PVC is created and no matching PV exists, the StorageClass provisioner automatically creates a PV.
What is the reclaim policy for PersistentVolumes?	`Delete`: PV and backing storage are removed. `Retain`: PV is kept for manual cleanup. `Recycle`: deprecated.
What is cert-manager?	A Kubernetes add-on that automates TLS certificate issuance and renewal. Supports Let's Encrypt, self-signed, CA-based, and Vault issuers.
What is a ClusterIssuer in cert-manager?	A cluster-scoped resource defining how certificates are issued. Unlike a namespaced Issuer, a ClusterIssuer can issue certificates for any namespace.
What is a CRD (Custom Resource Definition)?	A Kubernetes extension mechanism that lets you define new resource types. MetalLB's IPAddressPool, Gateway API's HTTPRoute, and cert-manager's Certificate are all CRDs.
How do CRDs and controllers relate to each other?	CRDs define the "what" (new resource types). Controllers are the "how" — they watch CRD instances and reconcile desired state with actual state.
What is the operator pattern in Kubernetes?	A controller that manages a complex stateful application using CRDs. Encodes domain knowledge (deploy, scale, backup, upgrade) as code.
What is the difference between a Kubernetes Deployment and a DaemonSet?	Deployment runs N replicas, scheduled wherever. DaemonSet runs exactly one pod per node. CNI agents and MetalLB speakers use DaemonSets.
What is the difference between a Deployment and a StatefulSet?	Deployment: pods are interchangeable (no stable identity). StatefulSet: each pod has a stable hostname (pod-0, pod-1), persistent storage, and ordered startup/shutdown.
What is a Kubernetes Service and why is it needed?	Provides a stable virtual IP (ClusterIP) for ephemeral pods. Pods' IPs change, but the Service IP is permanent. kube-proxy/Cilium load-balances traffic to backend pods.
How does ClusterIP translation work with Cilium/eBPF?	eBPF intercepts packets to a ClusterIP, selects a backend pod IP (load balancing), and rewrites the destination (DNAT) — all in the kernel, no userspace.
What is Hubble in the Cilium ecosystem?	Cilium's built-in network observability platform — flow logs, DNS queries, HTTP requests, drop reasons, and service maps collected from eBPF programs.
What are the three types of Kubernetes probes?	Startup (runs once at start), Liveness (kills container if fails), Readiness (removes from Service endpoints if fails). Each can use HTTP, TCP, or exec.
What does CrashLoopBackOff mean?	A pod keeps crashing and Kubernetes restarts it with exponentially increasing delays (10s→20s→40s→5min). Check logs with `kubectl logs --previous`.
What is anti-affinity in pod scheduling?	Prevents pods from scheduling on the same node (or zone). Used for HA — if one node fails, other replicas survive.
What is the chicken-and-egg problem with kube-proxy replacement?	Cilium needs the API server to watch Services. The API server is accessed via ClusterIP. ClusterIP translation is done by kube-proxy. Without kube-proxy, Cilium needs the API server's real IP directly (k8sServiceHost).
What are the three CIDRs in a default kubeadm cluster?	Pod CIDR (10.244.0.0/16), Service CIDR (10.96.0.0/12), and the node's LAN subnet (192.168.86.0/24).
How does traffic flow from internet → router → MetalLB → Gateway → Pod?	Router ARPs for LoadBalancer IP → MetalLB leader responds (or kernel responds if secondary IP) → packet arrives at node → Cilium DNAT to nginx Gateway pod → nginx matches HTTPRoute → forwards to backend pod.
Why does Envoy proxy crash on Raspberry Pi 4?	Envoy uses TCMalloc, which assumes a 48-bit virtual address space. The RPi4's Cortex-A72 has only 39-bit VA space. mmap calls fail with "MmapAligned() failed". Affects both Cilium Envoy and Envoy Gateway.
Why was Nginx Gateway Fabric chosen over Envoy Gateway for RPi4?	Envoy Gateway uses Envoy proxy as its data plane, which crashes on RPi4 due to the TCMalloc 48-bit VA issue. NGF uses nginx, which has no such limitation and works fine on ARM64.
What is Nginx Gateway Fabric (NGF)?	A CNCF project that implements the Kubernetes Gateway API using nginx as the data plane. The Helm chart installs a control plane and auto-creates a GatewayClass named "nginx".
How does NGF provision the data plane when you create a Gateway?	NGF automatically creates an nginx Deployment and a LoadBalancer Service in the same namespace as the Gateway. Each Gateway gets its own separate nginx instance.
Why does MetalLB L2 mode fail on WiFi with Google WiFi / Nest routers?	Google WiFi filters ARP responses for IPs not in its DHCP table. MetalLB L2 works by responding to ARP for LoadBalancer IPs, but the router silently drops those responses. ARP stays "(incomplete)" on clients.
What is a gratuitous ARP?	An unsolicited ARP reply broadcast by a host to announce its IP-to-MAC mapping. MetalLB sends gratuitous ARPs when it assigns a LoadBalancer IP to a node, but WiFi routers may filter them.
How do you fix MetalLB L2 on WiFi when the router filters ARP?	Add the MetalLB pool IP as a secondary address on the Pi's WiFi interface: `nmcli connection modify "$CONN" +ipv4.addresses 192.168.86.200/32`. The kernel then responds to ARP natively, which the router accepts.
What is a secondary IP address on a Linux interface?	An additional IP address assigned to an existing interface alongside its primary IP. The kernel responds to ARP for all IPs on the interface. Added via `ip addr add` or `nmcli connection modify +ipv4.addresses`.
What is a NodePort Service and when is it a useful fallback?	NodePort exposes a Service on every node's IP at a static port (30000-32767). Useful when LoadBalancer IPs aren't reachable (e.g., WiFi ARP filtering). Access via `<node-ip>:<nodeport>`.
What does `ufw default allow routed` do and why is it needed for Kubernetes?	Allows forwarded/routed packets through the firewall (FORWARD chain). Required because Cilium/kube-proxy DNATs external traffic to pod IPs, which involves packet forwarding. Without it, UFW drops the forwarded packets.
What is the difference between UFW's incoming, outgoing, and routed policies?	Incoming: packets destined for the host (INPUT chain). Outgoing: packets originating from the host (OUTPUT chain). Routed: packets being forwarded through the host to another destination (FORWARD chain).
What does `kubeadm reset` do?	Tears down the cluster on a node. Doesn't clean iptables rules or CNI configs — those need manual cleanup.
What command checks if cluster DNS is working?	Deploy dnsutils pod and run: `kubectl exec dnsutils -- nslookup kubernetes.default`. Should resolve to the API server's ClusterIP.
Why do Kubernetes and networking have so many layers?	Each layer solves one concern: pod IPs (CNI), service discovery (DNS/ClusterIP), load balancing (kube-proxy/Cilium), external access (MetalLB), traffic routing (Gateway/Envoy), TLS (cert-manager). Allows swapping components independently.
What is Helm and what problem does it solve?	Helm is the Kubernetes package manager. It packages related manifests (Deployment, Service, ConfigMap, etc.) into a "chart" with templated values, making installs, upgrades, and rollbacks a single operation instead of managing dozens of YAML files individually.
What is a Helm chart?	A directory (or archive) containing templated Kubernetes manifests, a `Chart.yaml` with metadata, a `values.yaml` with defaults, and optional helpers. Charts are versioned and distributed via Helm repositories.
What is the difference between `helm install` and `helm upgrade --install`?	`helm install` fails if the release already exists. `helm upgrade --install` installs if new, upgrades if existing — making it idempotent and safe for automation/CI.
What does `helm rollback <release> <revision>` do?	It reverts a Helm release to a previous revision. Helm stores release history as Secrets in the namespace, so you can roll back to any previous state.
Where does Helm store release state?	As Secrets (type `helm.sh/release.v1`) in the release's namespace. Each revision gets its own Secret, containing the rendered manifests and values for that version.
What is `helm template` useful for?	It renders chart templates locally without installing anything — useful for debugging, reviewing generated YAML, or piping output into `kubectl apply` or Flux Kustomizations.
What does `helm diff upgrade` do?	A Helm plugin that shows a diff of what would change if you ran `helm upgrade`, without actually applying changes. Essential for reviewing changes before upgrading in production.
What does `helm list -A` show?	All Helm releases across all namespaces, with their status (deployed, failed, pending-upgrade), chart version, app version, and revision number.
What is `helm repo update` and when do you need it?	It refreshes the local cache of all configured Helm chart repositories. Needed before installing/upgrading if new chart versions have been published.
What is Kustomize and how does it differ from Helm?	Kustomize is a template-free manifest customisation tool — it uses overlays, patches, and transformers to modify base YAML. Helm uses Go templates with values substitution. Kustomize is built into `kubectl apply -k`.
What are Kustomize bases and overlays?	A base is a directory with plain manifests and a kustomization.yaml. An overlay references a base and adds patches, labels, namespace overrides, etc. Common pattern: `base/` for shared config, `overlays/dev/`, `overlays/prod/` for environment-specific changes.
What Kustomize transformers are most commonly used?	`namePrefix`/`nameSuffix` (rename resources), `namespace` (override namespace for all resources), `commonLabels`/`commonAnnotations` (add to all resources), `images` (override container images), and `patches` (strategic merge or JSON patches).
What is `kubectl apply -k <dir>` vs `kubectl apply -f <file>`?	`-k` runs Kustomize build on the directory first, then applies the result. `-f` applies the raw file directly. `-k` lets you use kustomization.yaml overlays without a separate build step.
What is the difference between imperative and declarative k8s management?	Imperative: `kubectl create`, `kubectl run`, `kubectl edit` — you tell k8s what to do step by step. Declarative: `kubectl apply -f` — you declare the desired state in YAML and k8s figures out how to get there. GitOps extends declarative with Git as the source of truth.
What is server-side apply (SSA) in Kubernetes?	SSA tracks field ownership per manager, allowing multiple controllers to manage different fields of the same resource without conflicts. It replaced client-side apply (which could lose fields). Enabled with `kubectl apply --server-side`.
What is the difference between `kubectl apply` and `kubectl replace`?	`apply` does a three-way merge (last-applied, desired, live) and only changes fields you specify. `replace` deletes the entire resource and recreates it from your manifest — losing any fields added by controllers or other tools.
What are Kubernetes finalizers?	Metadata strings on a resource that prevent deletion until a controller removes them. Used for cleanup logic — e.g., a PVC finalizer ensures the underlying volume is deleted before the PVC object disappears.
What does `kubectl wait --for=condition=Ready` do?	It blocks until the specified condition is true on the resource, with an optional timeout. Useful in scripts and CI/CD pipelines for sequencing: e.g., wait for pods to be ready before running tests.
What is `kubectl port-forward` and when is it useful?	It tunnels a local port to a pod or service port inside the cluster. Useful for debugging/accessing internal services without creating a LoadBalancer or NodePort — e.g., accessing a database dashboard.
What is the difference between `kubectl logs` and `kubectl logs -f`?	`kubectl logs` dumps the current log output and exits. `-f` (follow) streams logs in real-time, like `tail -f`. Add `-p` (previous) to see logs from the last crashed container instance.
What does `kubectl get events --sort-by='.lastTimestamp'` show?	Cluster events sorted chronologically — scheduling decisions, image pulls, health check failures, OOM kills, etc. Essential for debugging why a pod is stuck in Pending or CrashLoopBackOff.
What is `kubectl describe` vs `kubectl get -o yaml`?	`describe` is human-readable with computed fields and events inlined. `get -o yaml` shows the raw API object (spec, status, metadata) — useful for machine processing or checking exact field values.
What does `kubectl diff -f <file>` do?	It shows a diff between the live resource in the cluster and the local manifest file, without applying changes. Similar to `terraform plan` — lets you preview what would change.
What is `kubectl top nodes` / `kubectl top pods`?	Shows real-time CPU and memory usage. Requires metrics-server to be installed in the cluster. Useful for capacity planning and spotting resource-hungry workloads.
What does `kubectl drain <node>` do?	It cordons the node (marks unschedulable) and evicts all pods respecting PodDisruptionBudgets. Used before maintenance — e.g., OS upgrade, hardware replacement.
What is the difference between `kubectl cordon` and `kubectl drain`?	`cordon` marks a node as unschedulable (no new pods) but leaves existing pods running. `drain` cordons AND evicts all pods. Use cordon for soft preparation, drain for full evacuation.
What does `kubectl taint` do?	It adds a taint (key=value:effect) to a node. Pods without a matching toleration won't be scheduled there. Effects: NoSchedule, PreferNoSchedule, NoExecute (evicts running pods too).
What is `kubectl auth can-i <verb> <resource>`?	Tests whether the current user/SA has permission to perform an action. E.g., `kubectl auth can-i create deployments --namespace production`. Add `--as=system:serviceaccount:ns:sa` to test other identities.
What is `kubectl config use-context <name>`?	Switches your active kubeconfig context — changing which cluster, user credentials, and default namespace kubectl uses. Essential when managing multiple clusters.
What is the KUBECONFIG environment variable?	It specifies one or more kubeconfig file paths (colon-separated). kubectl merges them, allowing you to access multiple clusters. Default is `~/.kube/config`.
How do you merge multiple kubeconfig files?	Set `KUBECONFIG=~/.kube/config:~/.kube/config-rpi:~/.kube/config-staging` and all contexts/clusters/users become available. Use `kubectl config get-contexts` to list them. Ensure names don't collide.
What is `kubectl config rename-context`?	Renames a context in your kubeconfig. Essential when merging configs from different clusters that all use generic names like `kubernetes-admin@kubernetes`.
What does `kubectl api-resources` show?	Lists all resource types the API server knows about — name, shortname, API group, namespaced (bool), and kind. Useful for discovering what CRDs are installed or finding the right resource name.
What is `kubectl explain <resource>.<field>`?	Shows built-in documentation for any API resource field. E.g., `kubectl explain pod.spec.containers.resources` describes CPU/memory requests/limits. Faster than browsing docs.
What is a Kubernetes label vs annotation?	Labels are for selection and filtering (used by selectors, Services, ReplicaSets). Annotations are for arbitrary metadata (used by tools, controllers, humans). Labels have stricter syntax rules.
What is `kubectl label` and `kubectl annotate`?	They add/update/remove labels and annotations on existing resources. E.g., `kubectl label pod foo env=prod`, `kubectl annotate svc bar description="main API"`. Add `--overwrite` to change existing values.
What are resource requests vs limits in Kubernetes?	Requests are the guaranteed minimum — the scheduler uses them for placement. Limits are the maximum — the container gets OOM-killed (memory) or throttled (CPU) if exceeded. Requests <= Limits.
What are the three QoS classes in Kubernetes?	Guaranteed (requests == limits for all containers), Burstable (at least one container has requests < limits), BestEffort (no requests or limits set). Under memory pressure, BestEffort pods are killed first, then Burstable, then Guaranteed.
What is a PodDisruptionBudget (PDB)?	A policy specifying the minimum number (or percentage) of pods that must remain available during voluntary disruptions (drain, upgrade). Protects availability — e.g., `minAvailable: 1` ensures at least one replica is always running.
What is `kubectl rollout status deployment/<name>`?	Shows the progress of a rolling update in real-time. Returns success once all new pods are up and old ones terminated. Useful in CI/CD scripts to wait for deployment completion.
What does `kubectl rollout undo deployment/<name>` do?	Rolls back to the previous ReplicaSet revision. Add `--to-revision=N` to roll back to a specific version. Kubernetes keeps old ReplicaSets (controlled by `spec.revisionHistoryLimit`) for this.
What is `kubectl create secret` vs declarative secrets?	`kubectl create secret generic foo --from-literal=key=value` is imperative — quick for ad-hoc secrets. Declarative means committing (encrypted) Secret manifests to Git. GitOps prefers declarative + SOPS/sealed-secrets.
What is the difference between ConfigMap and Secret in practice?	ConfigMaps store non-sensitive config (env vars, config files). Secrets store sensitive data (passwords, tokens, TLS certs) — base64-encoded, with slightly tighter RBAC defaults. Both can be mounted as volumes or env vars.
